{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [YOLO](http://pjreddie.com/darknet/yolo/): Real-Time Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkz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\ngIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgf/Z\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/K9a6mGNmhbc\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f905c4dffd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('K9a6mGNmhbc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO는 Pascal [VOC 2012 dataset](http://host.robots.ox.ac.uk:8080/pascal/VOC/)에 있는 객체를 검출하기 위한 시스템이다. 이 시스템은 20개의 Pascal object classes를 검출할 수 있다.\n",
    "\n",
    "- person\n",
    "- bird, cat, cow, dog, horse, sheep\n",
    "- aeroplane, bicycle, boat, bus, car, motorbike, train\n",
    "- bottle, chair, dining table, potted plant, sofa, tv/monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 작동 원리\n",
    "모든 **사전 검출 시스템들**은 검출 성능을 위해 classifier와 localizer를 개조하여 활용한다. 이 시스템들은 하나의 이미지에서 여러 위치와 크기를 가지는 영역들을 모델에 적용하여, 점수가 높게 나온 영역에서 검출한다.\n",
    "\n",
    "YOLO는 완전히 다른 접근법을 취한다. full image에 하나의 single neural network를 적용하여 이미지를 영역들로 나누고 각 영역에서 bounding boxes(경계박스)와 probabilites를 예측하다. 이러한 경계박스들은 예측된 probabilites에 의해 저울질된다.\n",
    "\n",
    "![YOLO 모델](http://pjreddie.com/media/image/model_2.png)\n",
    "\n",
    "마지막으로 검출에 대한 threshold 값을 지정하여, 높은 점수의 검출만을 뽑아낸다.\n",
    "\n",
    "![screen shot](http://pjreddie.com/media/image/Screen_Shot_2016-09-07_at_10.56.09_PM.png)\n",
    "\n",
    "YOLO는 다른 classifier기반 시스텝에 비해 여러모로 유리하다. test time에 full 이미지를 보고 이미지에 있는 global contex에 대한 정보를 예측한다. 또한, 하나의 single image에 대한 수천개의 이미지가 필요한 R-CNN-like 시스템과 달리, 하나의 single network을 가지고 예측을 수행하여, R-CNN보다는 1000 배, Fast R-CNN 보다는 100 배 이상 더 빠르다. (상세 내용은 논문 참조)\n",
    "\n",
    "![comparison](https://ai2-s2-public.s3.amazonaws.com/figures/2016-03-25/21a1654b856cf0c64e60e58258669b374cb05539/6-Table2-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 학습된 모델을 사용한 검출\n",
    "사전 학습된 모델을 사용하여 YOLO 시스템으로 객체 식별하는 방법\n",
    "1. [Darknet 설치](http://pjreddie.com/darknet/install/)<br>\n",
    "    - Darknet이 설치되면, cfg/ 서브디렉토리에 YOLO를 위한 config file이 있다.\n",
    "    - 몇가지 예제 이미지가 data/ 서브디렉토리에 있다.\n",
    "\n",
    "2. [기 학습된 모델의 weights(W) file](http://pjreddie.com/media/files/yolo.weights)(753MB) 다운로드 또는 아래 script 실행.\n",
    "\n",
    "    > $> wget http://pjreddie.com/media/files/yolo.weights <br>\n",
    "    \\$> ./darknet yolo test cfg/yolo.cfg yolo.weights data/dog.jpg\n",
    "\n",
    "3. YOLO example 수행\n",
    "\n",
    "weights file이 base 폴더에 있다고 가정할 때, data 폴더 내의 eagle.jpg, dog.jpg, person.jpg, horses.jpg 등으로 다음과 같이 YOLO를 실행한다.\n",
    "\n",
    "> $> ./darknet yolo test cfg/yolo.cfg yolo.weights data/dog.jpg <br>\n",
    "0: Crop Layer: 448 x 448 -> 448 x 448 x 3 image <br>\n",
    "1: Convolutional Layer: 448 x 448 x 3 image, 64 filters -> 224 x 224 x 64 image <br>\n",
    ".... <br>\n",
    "27: Connected Layer: 4096 inputs, 1225 outputs <br>\n",
    "28: Detection Layer <br>\n",
    "Loading weights from yolo.weights...Done! <br>\n",
    "data/dog.jpg: Predicted in 8.012962 seconds. <br>\n",
    "0.941620 car <br>\n",
    "0.397087 bicycle <br>\n",
    "0.220952 dog <br>\n",
    "Not compiled with OpenCV, saving to predictions.png instead <br>\n",
    "\n",
    "Darkent은 검출한 객체, 신뢰도, 검출시간을 출력한다. CPU에서 Darknet을 사용하였기 때문에 이미지당 6~12초가 걸렸는데, GPU를 사용했다면, 훨씬 더 빨랐을 것이다.\n",
    "\n",
    "OpenCV로 Darknet을 컴파일했다면 직접 그 결과를 확인할 수 있었겠지만, 그렇지 않았기 때문에 아래 그림과 같이 predictions.png 파일에 그 결과를 저장한다.\n",
    "\n",
    "![predictions.png](http://pjreddie.com/media/image/Screen_Shot_2016-09-07_at_10.56.09_PM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 다중 이미지 detection\n",
    "명령어 라인에서 이미지 파일을 직접 입력하는 대신, 여러 이미지를 한번에 테스트하기 위해 아래와 같이 실행한다.\n",
    "\n",
    "> \\$>./darknet yolo test cfg/yolo.cfg yolo.weights <br>\n",
    "0: Crop Layer: 448 x 448 -> 448 x 448 x 3 image <br>\n",
    "1: Convolutional Layer: 448 x 448 x 3 image, 64 filters -> 224 x 224 x 64 image <br>\n",
    ".... <br>\n",
    "27: Connected Layer: 4096 inputs, 1225 outputs <br>\n",
    "28: Detection Layer <br>\n",
    "Loading weights from yolo.weights...Done! <br>\n",
    "Enter Image Path: **data/eagle.jpg** <br>\n",
    "\n",
    "입력된 이미지에 대한 영역 boxs들과 영역 내의 객체를 예측한 후에는 또 다른 이미지 입력을 받기 위한 Image Path input 프롬프트가 나타난다. 종료하기 위해서는 [Ctrl][c]를 입력하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tiny Model\n",
    "tiny-yolo.cfg는 Darknet [reference network](http://pjreddie.com/darknet/imagenet/#reference)에 기반한다. cfg/ 서브디렉토리에 config file이 있는 상태에서 [기 훈련된 tiny model weight file](http://pjreddie.com/media/files/tiny-yolo.weights)(103MB)을 다운로드 하면, 아래 와 같이 tiny model을 실행한다.\n",
    "\n",
    "> $> wget http://pjreddie.com/media/files/tiny-yolo.weights <br>\n",
    "\\$> ./darknet yolo test cfg/tiny-yolo.cfg tiny-yolo.weights data/person.jpg\n",
    "\n",
    "![tinyModel](http://pjreddie.com/media/image/Screen_Shot_2016-09-07_at_11.00.34_PM.png)\n",
    "\n",
    "tiny YOLO 버전은 516MB의 GPU 메모리 만을 사용하여 Titan X에서는 150 fps 이상을 구동한다. **검출 threshold를 변경**하였다는 것에 주의하라."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO 모델 비교\n",
    "- yolo.cfg는 [extraction](http://pjreddie.com/darknet/imagenet/#extraction) network에 기반한다. 이는 45fps로 이미지를 처리하며, 이때의 weight files은 [2007train/val + 2012 train/val](http://pjreddie.com/media/files/yolo.weights)에서 학습되었다.\n",
    "- tiny-yolo.cfg는 훨씬 더 작고 [Darknet reference network](http://pjreddie.com/darknet/imagenet/#reference)에 기반한다. [2007train/val + 2012 train/val](http://pjreddie.com/media/files/yolo.weights)에서 학습된 weight files로 155fps 속도로 이미지를 처리한다.\n",
    "\n",
    "### 검출 threshold 변경하기\n",
    "디폴트로, YOLO는 .2 이상의 신뢰도를 가지고 검출된 objects 만을 표시한다. 이 threshold를 변경하려면 yolo 명령어로 -thresh <val> flag를 전달하면 된다. 예를 들어 threshold를 0으로 모든 검출을 표시하려면 다음과 같이 할 수 있다.\n",
    "\n",
    "> $> ./darknet yolo test cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0\n",
    "\n",
    "이 경우, 다음과 같은 결과를 출력하게 된다.\n",
    "\n",
    "![thresh=0](http://pjreddie.com/media/image/Screen_Shot_2016-09-07_at_10.55.25_PM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## VOC 2012에서 실시간 검출\n",
    "### CUDA에서 Darknet 컴파일\n",
    "[CUDA에서 Darknet을 컴파일](http://pjreddie.com/darknet/install/#cuda)하면, 처리 속도가 훨씬 빨라진다. 다중 이미지를 효과적으로 검출하기 위해 yolo의 `valid 서브루틴`을 사용할 수 있게 된다.\n",
    "\n",
    "1. 먼저, YOLO의 data를 가지고 Darknet을 위한 메타데이터를 생성해야 한다. [VOC 2012 test data](http://host.robots.ox.ac.uk:8080/eval/downloads/VOC2012test.tar)인 2012test.tar 파일을 다운로드하여 다음 명령을 실행한다.\n",
    "\n",
    "    ~~~bash\n",
    "    $> tar xf 2012test.tar\n",
    "    $> cp VOCdevkit/VOC2012/ImageSets/Main/test.txt .\n",
    "    $> sed 's?^?''pwd''/VOCdevkit/VOC2012/JPEGImages/?; s?$?.jpg?' test.txt > voc.2012.test\n",
    "    ~~~\n",
    "\n",
    "    위 명령은 데이터를 압축해제하고, test 이미지들의 전체 경로 리스트를 생성한다.\n",
    "\n",
    "2. 이 리스트를 darknet/data 서브디렉토리로 이동시키자.\n",
    "\n",
    "    ~~~bash\n",
    "    $> mv voc.2012.test <path-to>/darknet/data\n",
    "    ~~~\n",
    "\n",
    "    이제 뭔가를 검출할 준비를 마쳤다.\n",
    "\n",
    "3. 다음과 같이 yolo의 'valid 서브루틴'을 이용하여 전체 test 이미지를 검출해보자.\n",
    "\n",
    "    ~~~bash\n",
    "    $> ./darknet yolo valid cfg/yolo.cfg yolo.weights\n",
    "    ~~~\n",
    "\n",
    "    이미지들의 검출 결과는 아래와 같이 표시된다.\n",
    "    > .... <br>\n",
    "    10984 <br>\n",
    "    10992 <br>\n",
    "    Total Detection Time: 250.000000 Seconds\n",
    "\n",
    "VOC 2012 test set에 10991 개의 이미지가 있었다. 이 이미지들을 44fps의 속도로 단지 250 초만에 처리했다. 만약 [selective search](http://koen.me/research/selectivesearch/)를 사용했더라면, 모든 이미지에 대한 region proposal 만을 추출하는 데에도 6 시간이 걸렸을 것이다. CUDA를 사용한 YOLO에서는 전체 검출 pipeline을 처리하는데 단지 4분 여가 걸렸을 뿐이다. 예측 결과는 results/ 서브디렉토리에 [Pascal VOC submission](http://host.robots.ox.ac.uk:8080/) 포맷으로 저장된다.\n",
    "\n",
    "Pascal challenge에서의 기록을 재확인하는 정도라면, 단순히 [이때의 weight file](http://pjreddie.com/media/files/yolo.rescore.weights)(1.0GB)을 다운로드하면 된다. 이  파일은 논문에 서술한 IOU prediction으로 학습하였다.(논문에서는 mAP 점수가 다소 개선되었다.) 논문의 결과와 동일하지는 않지만, 거의 비슷한 결과를 확인할 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webcam에서의 실시간 검출\n",
    "아래 유튜브 동영상과 같이 웹캠으로부터 출력된 이미지 입력 스트림으로 구동해보자.\n",
    "\n",
    "[![Video Label](http://img.youtube.com/vi/r6ZzopHEO1U/0.jpg)](https://youtu.be/r6ZzopHEO1U?t=0s)\n",
    "\n",
    "이 데모를 직접 구동하기 위해서는 이전과 같이 [Darknet을 CUDA와 OpenCV로 컴파일](http://pjreddie.com/darknet/install/#cuda)해야 하고, 적절한 weight files을 가지고 있는 [YOLO config 파일](http://pjreddie.com/darknet/yolo/#models)이 필요하다. 준비가 되면 다음 명령어를 입력하여 실행한다.\n",
    "\n",
    "~~~bash\n",
    "$> ./darknet yolo demo cfg/yolo.cfg yolo.weights\n",
    "~~~\n",
    "\n",
    "아래와 같이 YOLO는 객체 식별을 위한 영역 박스가 덧붙여진 이미지 뿐 아니라, 현재 FPS와 예측된 class들을 보여준다.\n",
    "\n",
    "![detects](http://pjreddie.com/media/image/Screen_Shot_2015-11-17_at_11.19.40_AM.png)\n",
    "\n",
    "OpenCV가 연결할 수 있는 (컴퓨터에 연결된) webcam이 필요하다. 여러 webcam이 연결된 경우라면, flag `-c <num>`를 설정하여 선택할 수 있다.(OpenCV는 default로 webcam `0`를 사용한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO + COCO\n",
    "COCO는 MS에서 제공하는 80개의 카테고리를 가지는 큰 detection dataset이다. COCO에서 학습된 2개의 YOLO 모델이 있다. 이미지 객체를 식별을 위해 다음과 같이 COCO에서 학습된 tiny-YOLO를 수행할 수 있다.\n",
    "\n",
    "~~~bash\n",
    "$> git clone https://github.com/pjreddie/darknet\n",
    "$> cd darknet\n",
    "$> make\n",
    "$> wget http://pjreddie.com/media/files/tiny-coco.weights\n",
    "$> ./darknet coco test cfg/tiny-coco.cfg tiny-coco.weights data/giraffe.jpg\n",
    "~~~\n",
    "\n",
    "검출된 결과를 보기 위해, predictions.png 파일을 확인하라.\n",
    "\n",
    "![기린](http://pjreddie.com/media/image/Screen_Shot_2016-09-08_at_12.37.19_AM.png)\n",
    "\n",
    "tiny가 아닌 완전한 YOLO-COCO 모델을 이용할 수 있다.\n",
    "\n",
    "~~~bash\n",
    "$> wget http://pjreddie.com/media/files/yolo-coco.weights\n",
    "$> ./darknet coco test cfg/yolo-coco.cfg yolo-coco.weights data/giraffe.jpg\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO 학습시키기\n",
    "YOLO를 다른 학습 체계, 초월변수, datasets에 적용하기 위해, 다양한 학습 이미지로 훈련시킬 수 있다. 여기서는 예로서 Pascal VOC dataset에서 학습시켜 동작하도록 하는 방법을 제공하겠다.\n",
    "\n",
    "### Pascal VOC data 획득\n",
    "YOLO를 학습시키기 위해 [2007부터 2012까지의 VOC data](http://pjreddie.com/projects/pascal-voc-dataset-mirror/)가 필요하다. 이 데이터를 저장할 디렉토리를 생성하고, 여기서 아래 명령을 수행한다.\n",
    "\n",
    "~~~bassh\n",
    "curl -O http://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar\n",
    "curl -O http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
    "curl -O http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\n",
    "tar xf VOCtrainval_11-May-2012.tar\n",
    "tar xf VOCtrainval_06-Nov-2007.tar\n",
    "tar xf VOCtest_06-Nov-2007.tar\n",
    "~~~\n",
    "\n",
    "모든 VOC 학습 데이터는 VOCdevkit/ 서브폴더 안에 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOC에 대한 labels 생성하기\n",
    "Darknet이 사용할 label file들을 생성해야 한다. Darknet은 아래와 같이 한 라인에 각 이미지에 대한 ground truth 객체를 담고 있는 \\.txt 파일을 필요로 한다.\n",
    "\n",
    "~~~xml\n",
    "<object-class> <x> <y> <width> <height>\n",
    "~~~\n",
    "\n",
    "여기서 x, y, width, height는 이미지의 폭, 높이에 상대적인 값이다. 이러한 파일을 생성하기 위해서, Darknet의 scripts/ 폴더 내에 voc_label.py script를 구현해야 한다. 기 구현된 것을 바로 다운로드 해보자.\n",
    "\n",
    "~~~bash\n",
    "curl -O http://pjreddie.com/media/files/voc_label.py\n",
    "python voc_label.py\n",
    "~~~\n",
    "\n",
    "몇 분 후, 이 스크립트가 모든 소요 파일을 생성한다. 많은 label file들이 **VOCdevkit/VOC2007/labels/**과 **VOCdevkit/VOC2012/labels/** 안에 생성되어, 아래와 같은 디렉토리 구조에 저장된 것을 확인할 수 있다.\n",
    "\n",
    "~~~bash\n",
    "$> ls\n",
    "2007_test.txt   VOCdevkit\n",
    "2007_train.txt  voc_label.py\n",
    "2007_val.txt    VOCtest_06-Nov-2007.tar\n",
    "2012_train.txt  VOCtrainval_06-Nov-2007.tar\n",
    "2012_val.txt    VOCtrainval_11-May-2012.tar\n",
    "~~~\n",
    "\n",
    "2007_train.txt와 같은 text 파일에는 해당 이미지 set에 대한 이미지 파일 목록들이 나열되어 있다. Darknet은 학습할 모든 이미지가 있는 하나의 text 파일을 필요로 한다. 이번 예제에서는 모델을 test할 2012년 validation set을 제외한 모든 이미지 set으로 학습하도록 하자.\n",
    "\n",
    "~~~bash\n",
    "cat 2007_* 2012_train.txt > train.txt\n",
    "~~~\n",
    "\n",
    "train.txt에 학습할 모든 image file들을 나열한 하나의 큰 data list를 생성하였다. 이것으로 data 설정에 필요한 모든 것을 마무리하였다.\n",
    "\n",
    "<font color=\"red\">[역자 주]</font>** 만약, 전혀 새로운 데이터로 부터 학습을 하기 위해서는** 각 이미지의 각 위치에 각 객체를 식별하는 라벨을 모두 지정하는 image set - label set의 짝을 인위적으로 모두 생성해야하며, 이는 전문적으로 수련된 작업자에 의해 수공으로 이뤄져야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darknet을 Pascal Data에 위치시키기\n",
    "이제 Darknet 디렉토리로 이동하자. yolo의 train 서브루틴을 변경하여 학습시키고자 하는 VOC data의 위치를 가르키도록 해야한다. src/yolo.c 파일의 18, 19 line을 아래와 같이 편집한다.\n",
    "\n",
    "~~~c\n",
    "18     char *train_images = \"/home/pjreddie/data/voc/test/train.txt\";\n",
    "19     char *backup_directory = \"/home/pjreddie/backup/\";\n",
    "~~~\n",
    "\n",
    "train_images는 머징한 train.txt를 가르키도록하고, backup_directory는 훈련동안 weights 파일을 백업할 위치를 지정한다. 편집이 끝나면, Darknet을 다시 make 해줘야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기 학습된 Convolutional Wights 다운로드\n",
    "training을 위해, Imagenet에서 기 학습된 convolutional weights를 사용한다. [Extraction model](http://pjreddie.com/darknet/imagenet/#extraction)에서 이 weights(86MB)를 사용하기 위해 [여기](http://pjreddie.com/media/files/extraction.conv.weights)서 다운로드 한다.\n",
    "\n",
    "tiny 모델을 학습하고자 한다면, [darknet reference network convolutional weights](http://pjreddie.com/media/files/darknet.conv.weights)(25MB)를 다운로드 하면 된다.\n",
    "\n",
    "자체로 기 학습된 weights를 생성하려면, 기 학습된 [Extraction model](http://pjreddie.com/darknet/imagenet/#extraction)을 다운로드 하여 다음 명령을 실행한다.\n",
    "\n",
    "~~~bash\n",
    "./darknet partial cfg/extraction.cfg extraction.weights extraction.conv.weights 24\n",
    "~~~\n",
    "\n",
    "weights file을 다운로드만 하는거라면, 더 쉽다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습하기\n",
    "마침내 학습할 준비가 완료되었다. Run:\n",
    "\n",
    "~~~bash\n",
    "./darknet yolo train cfg/yolo.train.cfg extraction.conv.weight\n",
    "~~~\n",
    "\n",
    "It should start spitting out numbers and stuff.\n",
    "\n",
    "#### 훈련 중 체크포인트\n",
    "매 128,000 이미지 마다, Darknet은 학습 체크포인트를 src/yolo.c에서 지정한 디렉토리에 yolo_12000.weights와 같은 이름으로 저장한다. scratch(랜덤 초기화값?)로 부터 시작하지 않고, 이 것을 이용하여 훈련을 재시작할 수 있다.\n",
    "\n",
    "매 40,000 반복(batches) 마다, Darknet은 최종 model weights를 yolo_final.weights로 저장한다. 이때 학습을 마치면 된다.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 논문: [You Only Look Once: Unified, Real-Time Object Detection](http://arxiv.org/pdf/1506.02640v5.pdf)\n",
    "by Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi\n",
    "\n",
    "## 초록\n",
    "YOLO는 object detection의 새로운 접근법이다. 기존에는 검출을 위해 classifier를 변경하였지만, YOLO는 공간적으로 독립된 사각형 박스에 대한 회귀문제로 틀을 짜고, 이 박스에서 class probability를 계산하는 방법을 사용한다. 하나의 단일 neural network이 박스를 예측하고, 한번의 평가로 전체 이미지들로부터 직접 class 확률을 예측한다. 전체 검출 pipeline이 하나의 single network에서 이뤄지기 때문에, 이 네트워크 만으로 전체 성능 향상 최적화를 이룩할 수 있다.\n",
    "\n",
    "무쟈게 빨라서, **기본 YOLO 모델은 실시간으로 45fps로 이미지를 처리**할 수 있다.좀 더 작은 버전인 **fast YOLO는 다른 실시간 검출기보다 2배의 mAP를 유지하면서도 놀랍게도 155fps를 처리**할 수 있다. 최신 검출 시스템과 비교해 볼 때, 더 많은 localization error를 가지지만, 배경에 의한 False Positive(이하 FP)가 더 적다. YOLO는 객체에 대해 매우 일반적인 representations을 학습한다. 이때문에 자연 이미지 뿐 아니라, 삽화등 인공 이미지(artwork)를 망라할 때 DRM이나 R-CNN 등의 다른 검출 방법보다 압도적인 성능을 일반적으로 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 소개\n",
    "사람이 이미지를 한번 보면, 어떤 객체들이, 어느 위치에서 어떤 상호작용을 하는 지 바로 알아챈다. 인간의 지각 시스템은 빠르고 정확해서 다이빙 같은 복잡한 판별 작업을 별 어려움없이 수행해낸다. 객체 검출 시스템에 있어서의 빠르고 정확한 알고리즘은 컴퓨터가 특별한 센서없이도 차량을 운전하거나, 도우미 장치가 사용자에게 실시간 장면 정보를 제공하고, 범용으로 응답처리를 할 수 있는 로봇을 가능하게 할 수 있다.\n",
    "\n",
    "현재 (이미지 객체)검출 시스템은 객체를 식별하기 위해 test 이미지에서 다양한 위치와 크기에서 그 객체를 위한 분류기(classifier)로 객체를 평가한다.\n",
    "\n",
    "DPM(Deformable part models)같은 시스템은 <U>전체 이미지에 걸쳐 동일한 간격의 locations에서 분류기가 동작하도록 sliding window 접근법</U>을 사용한다.\n",
    "\n",
    "R-CNN 같은 보다 최근의 접근법은 \n",
    "1. region proposal method를 사용하여 잠재적인 경계박스를 생성하고, 이 박스 위에 분류기를 돌린다.\n",
    "2. 분류 후, 후처리 시스템으로 경계박스를 정재하고, 중복된 검출을 제거하고 동일 scene 내의 다른 객체에 대한 경계박스들을 재평가한다.\n",
    "\n",
    "이러한 복잡한 pipeline들은 개별 component 별로 독립적으로 훈련하기 때문에, 느리고 최적화하기 쉽지 않다.\n",
    "\n",
    "YOLO는 객체 검출 문제를 \n",
    "1. 단일 회귀문제로 재구성하여, 이미지 픽셀로 부터 직접적으로 경계박스 좌표를 구하고\n",
    "2. 이 박스에서 분류 확률을 구한다.\n",
    "\n",
    "이와 같이 하면, 어떠한 객체들이 어느 위치에 있는지 예측하기 위해 이미지를 한번만 볼 뿐이다.\n",
    "![이미지](https://ai2-s2-public.s3.amazonaws.com/figures/2016-03-25/21a1654b856cf0c64e60e58258669b374cb05539/1-Figure1-1.png)\n",
    "\n",
    "**[그림 1]: YOLO Detection System.** YOLO로 이미지를 처리하는 것은 단순하고 직접적이다. YOLO는 (1) 입력 이미지를 $448 \\times 448$로 resizing하고, (2) 단일 convolutional network를 이 이미지에서 구동하여, (3) 검출 결과를 모델의 기준 신뢰도에 의해 제한한다(thresholds the resulting detections by\n",
    "the model’s confidence).\n",
    "\n",
    "위 그림에서 보듯이, 단일 convolutional network는 여러 경계박스를 추출하고 각 박스에 대한 class 확률 예측을 한번에 수행한다. YOLO는 전체 이미지에서 훈련하고 검출 성능을 직접 최적화한다. 이러한 통합된 모델은 전통적인 모델에 비해 여러모로 유익하다.\n",
    "1. 단일 회귀로 검출을 재구성하기에 복잡한 pipelines을 가지는 전통적인 모델에 비해 YOLO는 매우 빠르다. base YOLO는 Titan X를 이용하여 배치 프로세싱없이 45fps를, fast YOLO는 150fps 이상을 수행한다. 이는 25ms의 지연으로(거의 실시간으로) 비디오 스트림을 처리할 수 있다는 것이다. 게다가, 다른 실시간 시스템에 비해 2배 이상의 mAP 성능까지도 제공한다. (http://pjreddie.com/yolo/) 에서 웹캠 영상에서 객체들을 실시간 검출하는 데모를 감상하시라.\n",
    "2. 예측 문제에서 범용적으로 활용할 수 있다. sliding window나 proposal기반 기술과는 달리, 훈련과 테스트 때 (input의) 전체적인(entire) 이미지를 보기 때문에, 이미지 외관(appearance) 뿐 아니라, class에 대한  contextual information을 인코딩할 수 있다(역자 주 - 동영상에서 경계박스와 객체명을 삽입한 것). 최고의 검출 방법인 fast R-CNN은 <font color='red'>[qst]</font> mistakes background patches in an image for objects because it can't see the larger context. YOLO는 Fast R-CNN에 비해 background error가 절반 이하다.\n",
    "3. YOLO는 객체에 대해 일반화할 수 있는 representations을 학습하기 때문에 예측하지 못한 입력이나 새로운 도메인에서도 쉽게 무너지지 않는다. 이때문에, 자연적 이미지로 학습하고, 인공물에 대해 테스트할 때, YOLO는 DRM이나 R-NN과 같은 전통적인 top 검출 시스템에 비해 압도적인 성능을 낸다. \n",
    "\n",
    "YOLO는 아직 정확도에 있어서는 최신 검출 시스템에 비해 뒤쳐진다. 이는 이미지에 있는 객체를 식별하는 동안, 특히 작은 객체의 위치를 미세하게 찾기위해 애쓰기 때문이다. 이러한 tradeoff에 대해서는 좀 더 검사할 것이다.\n",
    "\n",
    "훈련과 테스트를 위한 모든 코드는 오픈 소스다. 다양한 기 학습 모델을 다운로드하여 상업용으로도 이용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. 통합된 검출\n",
    "객체 검출을 위한 개별 기능단위(components)들을 (R-CNN 등과 달리)단일 NN으로 통합하였다. YOLO는 전체적인 이미지로 부터 각 경계박스를 예측하기 위해, features를 사용한다. 동시에 모든 경계박스에서 class probabilites를 예측한다. 이것이 의미하는 바는, YOLO가 전체 이미지와 그 이미지 내에 있는 모든 객체를 전역적으로(globally) 추론한다는 것이다. 이러한 YOLO의 디자인은 end-to-end 훈련과 high average precision을 유지하면서도 실시간 속도를 가능하게 한다.\n",
    "\n",
    "YOLO는 입력 이미지를 $S \\times S$ grid로 나눈다. 객체의 중앙이 한 grid cell에 있으면(If the center of an object falls into a grid cell), 그 grid cell이 객체 검출에 대한 책임을 가진다(that grid cell is responsible for detecting that object).\n",
    "\n",
    "각 grid cell은 **B 개의 경계박스와 그 박스들에 대한 신뢰점수들를 예측**(Each grid cell predicts B bounding boxes and confidence scores for those boxes)한다. 이러한 신뢰점수들은, 그 박스가 객체를 포함하고 있다는 모델 예측에 대한 신뢰도와 정확도를 반영한다.\n",
    "\n",
    "$$ Confidence: Pr(Object) * {IOU}^{truth}_{pred} $$   \n",
    "<font color='red'>[qst] </font>그렇다면, grid cell당 B개의 신뢰도가 있는가?\n",
    "\n",
    "그 cell 안에 객체가 없다면, Confidence Score들은 0이 되어야 한다. 만약 있다면(otherwise),  Confidence Score가 [예측하고 있는 box와 **갈려진 객체**(?; ground truth) 사이의 (교집합)intersection over union(IOU)의 값]과 같기를 바란다.(역자 주 - Pr(Object) ~1)\n",
    "(역자 - 첨언: 전체 이미지에서 실제 각 객체 이미지 edge는 박스가 아니지만 우리는 경계 **박스**로 이미지를 판정하므로, 잘 고려된 박스라도 그 내부의 grid cell 중에는 ${IOU}^{truth}_{pred} \\sim 0$인 cell 꽤 될 것이다.)\n",
    "\n",
    "각 경계박스는 5개의 예측 값(x, y, w, h, Confidence)으로 구성된다.\n",
    "- (x, y): grid cell의 경계에 대해 상대적인 경계박스의 중심 좌표(the center of the box relative to the bounds of the grid cell)\n",
    "- (w, h): 전체 이미지 대비 상대적인, 예측된 (경계박스의) 폭과 높이\n",
    "- Confidence: 예측된 (경계)박스와 임의의(any) ground truth(실제 Object를 구성하는) 박스 사이의 IOU(전체에 대한 교집합 비율)\n",
    "\n",
    "또한 각 grid cell은 C개의 conditional class probabilitiy: $ Pr(Class_i | Object) $를 예측한다. 이 확률은 객체를 포함하는 grid cell에 대한 조건부 확률이다. 이때 박스의 수 B와 무관하게 grid cell 당 하나의 class set에 대한 확률을 예측할 뿐이다.\n",
    "\n",
    "테스트 때에는 조건부 class 확률들을 개별 박스 신뢰도와 곱하는 데,\n",
    "\n",
    "$$ Pr(Class_i | Object) * Pr(Object) * {IOU}^{truth}_{pred} = Pr(Class_i) * {IOU}^{truth}_{pred}\\ \\quad \\quad \\quad (1)$$ \n",
    "\n",
    "이 값은 <U>각 박스에 대한 class별 신뢰도 점수</U>이다. 이 점수는 박스 내에서 보이는 그 class의 확률과 박스가 얼마나 객체를 잘 맞추는가를 모두 표현한다.\n",
    "\n",
    "![이미지](../YOLO_model.png)\n",
    "\n",
    "**[그림 2]: 모델.** 회귀 문제로 검출을 모델한다. 이미지를 $S \\times S$ grid로 나누고 각 grid cell에 대해 B개의 경계박스와 이러한 경계박스들에 대해 신뢰도와 C개의 class 확률을 예측한다. 이러한 예측은 입력 이미지당 $S \\times S \\times (B*5+C)$ **출력 tensor**로 표현된다.\n",
    "\n",
    "<U>PASCAL VOC에서 YOLO를 평가</U>할 때, S = 7, B =2, C = 20(PASCAL VOC는 20개의 class가 있음)을 사용하여 prediction은 이미지당 7 x 7 x 30 tensor 였다.\n",
    "\n",
    "![2-1](https://ai2-s2-public.s3.amazonaws.com/figures/2016-03-25/21a1654b856cf0c64e60e58258669b374cb05539/1-Figure2-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Network Design\n",
    "GoogLeNet을 변형한 convolutional NN로 구현하였는데, 초기 convolutional Layers는 이미지에서 features를 추출하고, FC layers에서는 class 확률과 좌표를 출력한다.\n",
    "망 구조는 24개의 ConvNet Layers와 2개의 FC Laysers로 구성되어 있다. GoogLeNet에서 사용되는 inception 모듈 대신에 3 x 3 conv Layer 뒤에 1 x 1 reduction layer를 두고 있다.\n",
    "\n",
    "![3](https://raw.githubusercontent.com/sunshineatnoon/Paper-Collection/master/images/YOLO.png)\n",
    "\n",
    "**[그림 3]: 아키텍쳐** 24개의 Conv Layer와 2개의 FC layers로 구성된다. 이전 layer의 features space(특히 depth)를 줄이기 위해 1 x 1 conv layer를 선택적으로 사용한다. <U>ImageNet 분류 task(절반의 해상도를 갖는 224 x 224)에서 학습</U>할 때, 해상도를 2배로 키워서 작업했다.  <font color=\"red\">[qst]:</font> (448 - 7 +2P)/S + 1 = 224? (역자 - 주) P=3, S=1로 448이 그대로 나온다. 다만, Max Pool 2개로 feature slice length를 두번 절반씩 줄였다.\n",
    "\n",
    "Fast YOLO는 9개의 Conv Layers와 더 적은 수의 filters를 사용한다. Network의 size를 제외하곤, 모든 학습 및 테스팅 파라미터가 동일하다.\n",
    "\n",
    "최종 출력은 7 x 7 x 30 예측 tensor이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.2 학습\n",
    "<U>1000-class ImageNet에서 YOLO를 사전학습</U>하였다. 사전학습동안 [그림 3]의 ConvNet에서 첫 20개의 layer를 사용한 후에 1개의 average pooling layer와 1개의 FC layer를 구성하였다. 1주일간 학습하여 ImageNet 2012 validation set에 대해 88%의 top-5 정확도를 가지게 되었으며, GoogLeNet에 준하는 정도이다. 학습과 추론 전과정은 Darknet 프레임워크를 사용한다.\n",
    "\n",
    "그리고 나서 검출 성능을 위해 모델을 변경한다. <U>Ren et al.[29]은 사전학습된 ConvNet에 conv layer와 FC layer를 추가할 때 성능이 개선됨을 보였다.</U> 이를 반영하여 4개의 Conv layes와 2개의 FC layers(임의 초기 W값을 가지는)를 추가하였다. 검출은 종종 fine-gained visual information을 요구하므로, 입력의 해상도를 224 x 224에서 448 x 448로 증가시켰다.\n",
    "\n",
    "최종 layer는 class 확률과 경계박스 좌표를 모두 예측한다. 경계박스의 폭과 높이를 이미지의 폭과 높이로 정규화한다.[0, 1] 또한, 경계박스 x, y 좌표도 particular grid cell 위치의 offsets이 되도록 파라미터화하여 결국 x, y도 [0, 1]로 제한된다.\n",
    "\n",
    "최종 layer에 선형 활성함수를 사용하고 다른 layers에서는 다음과 같은 leaky ReLU를 활성함수로 사용한다.\n",
    "\n",
    "$$\\phi (x)=\\begin{cases} x,\\quad \\quad if\\quad x>0 \\\\ 0.1x,\\quad otherwise \\end{cases}\\quad \\quad \\quad \\quad \\quad (2)$$\n",
    "\n",
    "회귀문제이므로 출력으로부터의 SSE를 최적화하지만, 이것이 평균 precision을 최대화하려는 목적과 완벽히 부합하지는 않는다. \n",
    "1. localization(위치) 에러와 분류 에러를 동일한 무게로 다루는 것은 이상적이지 않다.\n",
    "2. 또한 일반적으로 많은 grid cell들은 어떤 객체도 포함하지 않는다.\n",
    "    이는 해당 cell에서의 confidence score를 0으로 가게 하고\n",
    "    이로 인해 객체를 포함하는 cell의 gradient를 강화하게 한다.\n",
    "3. 이로인해 모델이 불안정하고, 초기 학습중에 발산하도록 유발한다.\n",
    "\n",
    "이를 경감시키기 위해, \n",
    "1. 경계박스 좌표 예측 손실을 증가시키고 $(\\lambda_{coord} = 5)$\n",
    "2. 객체를 포함하지 않는 박스에 대한 신뢰도 예측 손실을 줄였다. $(\\lambda_{noobj} = .5)$\n",
    "3. 큰 박스와 작은 박스에서 오는 손실의 기여도도 동등하게 여겼다.\n",
    "    큰 박스에서의 작은 편향 보다는 작은 박스에서의 그것이 더 중요하다.\n",
    "    이를 위해 w, h를 직접 예측하지 않고, $\\sqrt w, \\sqrt h$를 예측한다.\n",
    "\n",
    "YOLO는 grid cell에서 여러 개(B)의 경계박스를 예측하지만, 학습동안에 각 객체에 대해 책임을 지우도록 하기 위해, 현재 groud truth와의 IOU가 최대인 1개의 경계박스 predictor를 할당한다. 이로 인해 경계박스 predictor들 간에 전문성을 갖도록 유도한다. 이로 인해 각 predictor들은 객체의 size, ratios, classes를 더 잘 예측하게 되고, 전체적으로 recall을 향상시키도록 한다.(recall: 긍정의 예측률, 재현율)\n",
    "\n",
    "(역자 주 - 1개의 grid cell이 2개 이상의 객체 모두에서 IOU값이 최대라면, class confidence score가 가장 높은 1개의 객체만 식별되고, 나머지는 식별되지 못할 수도 있다.)\n",
    "\n",
    "학습동안 다음과 같은 다항 손실 함수(식 3)를 최적화한다.\n",
    "![loss function](http://cfile6.uf.tistory.com/image/224F6B46565E8B4B3229D3)\n",
    "$1_i^{obj}$ : cell ***i***에 object가 있는 지 여부<br>\n",
    "$1_{ij}^{obj}$ : cell ***i***에 있는 경계박스 ***j*** predictor가 예측 책임을 갖는다.\n",
    "\n",
    "손실 함수 설명:\n",
    "- grid cell에 객체가 있을 때만(conditional class probability), classification error를 갖는다.\n",
    "- ground truth 박스를 책임지는 (가장 큰 IOU를 가지는)predictor에 대해서만 경계박스 좌표 에러를 갖는다.\n",
    "\n",
    "학습동안에 135 epoch를 거쳐서, PASCAL VOC 2007/ 2009에서 평가하였다. 2012에서 테스트할 때는 학습을 위해 VOC 2007 test data를 포함하였다. 학습 내내 batch size = 64, momentum = .9, decay = .0005를 사용하였다.\n",
    "\n",
    "학습률 스케쥴은 다음과 같다:\n",
    "- 첫 epoch 동안은 학습률을 $10^{-3} ~ 10^{-2}$로 서서히 증가시켰다가\n",
    "- 75 epoch 까지 $10^{-2}$를 유지한 후, \n",
    "- 30 epoch 동안 $10^{-3}$로 한 후,\n",
    "- 마지막 30 epoch 동안 $10^{-4}$로 하였다.\n",
    "\n",
    "overfitting을 파하기 위해, dropout과 extensive data augmentation을 사용하였다. \n",
    "- 1st connected Layer 뒤에 .5 rate의 dropout layer를 두었고,\n",
    "- 원본 이미지 사이즈의 20% 까지 random scaling과 translation을 적용하였다.\n",
    "- HSV 에서 1.5배 까지 exposure와 saturation을 임의 조정하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.3 Inference\n",
    "PASCAL VOC에서 test시, 이미지당 98개의 경개박스에서 박스명 class 확률을 예측한다. YOLO는 test시 single network evaluation을 하므로, 극단적으로 빠르다.\n",
    "\n",
    "grid 설계 방법은 경계박스 예측에서 공간적 발산을 유발한다. 이는 객체를 온전히 담고 있는 grid box에서, YOLO는 명백히 객체에 대한 하나의 박스만을 예측한다.~~(이 경우, ground truth box는 더 작을 수 있다.)~~ 그러나, 더 큰 객체 또는 다중 셀의 경계에 걸쳐 있는 객체는 여러 셀에 의해 localized 되기 쉽다. Non-maximal suppression은 이러한 다중 검출을 교정하기 위해 사용된다. R-CNN이나 DPM과 마찬가지로, 성능에 지장이 없는한 Non-maximal suppression은 2~3% 정도 mAP를 향상시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 YOLO의 한계\n",
    "YOLO는 각 grid cell이 단지 2개의 경계박스 만을 예측하고, 1개 만의 class를 예측하므로, 경계박스 예측에 있어 공간적인 제약를 가지고 있다. 이로 이해 모델이 예측할 수 있는 근접 객체 수에 한계가 있다. 새떼와 같은 객체군에서 작은 객체를 식별하는데 어려움이 있다.\n",
    "\n",
    "데이터로 부터 경계박스를 예측하기 위해 학습하기 때문에, 새로운 환경이나 자세에 있는 객체를 일반화하도록 노력한다. 또한, 입력 이미지로 부터 여러번의 downsampling layers를 거치면서 다소 coarse features를 사용하는 면이 있다.\n",
    "\n",
    "마지막으로 검출 성능을 근사하는 손실 함수로 학습하는 동안, 작은 경계박스와 큰 경계박스에서 동등한 비율로 에러를 다룬다. 주요한 에러의 원인은 잘못된 localization이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 다른 검출 시스템과의 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 시험 결과\n",
    "\n",
    "### VOC 2007 Error 분석\n",
    "\n",
    "- Correct: correct class and IOU > .5\n",
    "- Localization: correct class, :1 < IOU < .5\n",
    "- Similar: class is similar, IOU > .1\n",
    "\n",
    "## Combining Fast R-CNN and YOLO\n",
    "![combine](https://ai2-s2-public.s3.amazonaws.com/figures/2016-03-25/21a1654b856cf0c64e60e58258669b374cb05539/5-Table1-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
