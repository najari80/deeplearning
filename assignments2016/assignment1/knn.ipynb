{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor (kNN) 연습\n",
    "\n",
    "*이 워크시트를 완성하고 제출하세요. (출력물과 워크시트에 포함되지 않은 코드들을 포함해서) 더 자세한 정보는 코스 웹사이트인 [숙제 페이지](http://vision.stanford.edu/teaching/cs231n/assignments.html)에서 볼 수 있습니다.*\n",
    "\n",
    "kNN 분류기는 다음 두 단계로 구성됩니다.\n",
    "\n",
    "- 학습중에, 분류기는 데이터를 학습하고 그것을 기억합니다.\n",
    "- 테스트중에, KNN은 모든 이미지를 훈련된 이미지와 k 번째 레이블을 전송하는 가장 유사한 훈련 예와 비교합니다.\n",
    "- k의 값은 교차 검증되었습니다.\n",
    "\n",
    "이번 연습에서 우리는 이러한 단계들을 수행하고 \n",
    "간단한 이미지 분류기 pipeline, 교차검증을 이해하고, 효율적인 벡터화된 코드를 작성하는 방법을 알아봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 이 notebook을 위해 몇가지 설치 코드를 실행하세요.\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# matplotlib figure들을 새 창에서 뛰우지 않고 이 notebook에서 하기 위한 약간의 마법입니다.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# 이 notebook이 외부 파이썬 모듈을 재호출하기위한 코드입니다.\n",
    "# 다음 링크를 확인해 보세요. http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CIFAR-10 데이터를 불러옵니다.\n",
    "cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# sanity 체크로서 학습 데이터와 테스트 데이터의 크기를 출력합니다.\n",
    "print 'Training data shape: ', X_train.shape\n",
    "print 'Training labels shape: ', y_train.shape\n",
    "print 'Test data shape: ', X_test.shape\n",
    "print 'Test labels shape: ', y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 데이터셋에서 몇 가지 예제를 시각화 합니다.\n",
    "# 각 class마다 약간의 학습 이미지를 보여줍니다.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 이 연습에 더 효율적인 코드 실행을 위한 데이터를 표본\n",
    "num_training = 5000\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "num_test = 500\n",
    "mask = range(num_test)\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 이미지 데이터를 행으로 변형시킵니다.\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "print X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cs231n.classifiers import KNearestNeighbor\n",
    "\n",
    "# kNN 분류기를 생성합니다.\n",
    "# kNN분류기를 학습시킬때 분류기는 단순히 데이터를 기억하고\n",
    "# 더 이상의 처리를 하지 않는다는것을 기억하세요.\n",
    "classifier = KNearestNeighbor()\n",
    "classifier.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 테스트데이터를 kNN 분류기로 분류해볼껍니다.\n",
    "이 과정을 두 단계로 분류할 수 있습니다:\n",
    "\n",
    "1. 먼저 모든 테스트 예제와 모든 훈련 예제 사이의 거리를 계산해야 합니다.\n",
    "2. Given these distances, for each test example \n",
    "we find the k nearest examples and have them vote \n",
    "for the label\n",
    "\n",
    "모든 테스트 예제와 학습 예제 사이의 거리 행렬을 계산하는 것 부터 시작해 봅시다. **Ntr** 학습 예제와 **Nte** 테스트 예제가 있을 때, 각 (i, j) 요소가 i번째 테스트와 j번째 훈련 예제의 거리를 나타내는 **Nte x Ntr** 행렬을 결과로 얻을 수 있습니다.\n",
    "\n",
    "\n",
    "먼저 `cs231n/classifiers/k_nearest_neighbor.py`를 열고 각 (테스트, 학습) 예제를 계산하는데 (매우 비효율적인) 이중 반복문을 사용한  `compute_distances_two_loops`를 구현해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cs231n/classifiers/k_nearest_neighbor.py를 열고\n",
    "# compute_distances_two_loops를 구현해 보세요.\n",
    "\n",
    "# 구현을 테스트해보세요.\n",
    "dists = classifier.compute_distances_two_loops(X_test)\n",
    "print dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 거리 행렬을 시각화 할 수 있습니다: 각 행은 하나의 시험 예제와 훈련 예제의 거리\n",
    "plt.imshow(dists, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**연습문제 #1** 일부 행, 열이 더 밝게 가시화 된 거리 행렬의 구조화된 패턴에 주목하세요. (기본 색상에서 검은 색은 낮은 간격을 나타내는 반면, 흰색은 높은 간격을 나타내는 것에 주목하세요.)\n",
    "\n",
    "- 뚜렷하게 밝은 행의 데이터가 그렇게 표시된 원인은 무엇일까요?\n",
    "- 열은 어떤 원인 때문에 저럴까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**당신의 답**: *여기에 쓰세요*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 이제 predict_labels를 구현해보고 아래의 코드를 실행해 보세요.\n",
    "# k = 1 을 사용합니다.(가장 가까운 이웃으로)\n",
    "y_test_pred = classifier.predict_labels(dists, k=1)\n",
    "\n",
    "# 예측 예제의 정확도를 계산하고 출력하세요.\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print 'Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 대략 `27%`정도의 정확도를 예상합니다. 이제 `k = 5`같은 좀더 큰 `k`에 대해서도 실행해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict_labels(dists, k=5)\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print 'Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`k = 1`보다 약간 더 좋은 성능을 기대할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 이제 부분 벡터화와 단일 반복문을 사용하여 거리 행렬의 계산 속도를 높일 수 있습니다.\n",
    "# compute_distance_one_loop를 구현해보고 아래의 코드를 실행해 보세요.\n",
    "dists_one = classifier.compute_distances_one_loop(X_test)\n",
    "\n",
    "# 우리의 벡터화 구현이 맞다는것을 보장하기 위해, \n",
    "# 우리는 navie한 구현을 확인해야 합니다.\n",
    "# 두 행렬의 유사 여부를 결정하는 방법은 여러가지가 있습니다.\n",
    "# 단순한 방법은 Frobenius norm입니다.\n",
    "# 이 Frobenius norm의 두 행렬은 모든 원소의 차이의 제곱합의 제곱근 입니다.\n",
    "# 다른 말로 하면, 행렬을 벡터로 변형하고 유클리드 거리를 계산합니다.\n",
    "difference = np.linalg.norm(dists - dists_one, ord='fro')\n",
    "print 'Difference was: %f' % (difference, )\n",
    "if difference < 0.001:\n",
    "  print 'Good! The distance matrices are the same'\n",
    "else:\n",
    "  print 'Uh-oh! The distance matrices are different'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 이제 compute_distances_no_loops 안의 완전히 벡터화된 버전을 구현하고 실행합니다.\n",
    "dists_two = classifier.compute_distances_no_loops(X_test)\n",
    "\n",
    "# 거리 행렬이 우리가 전에 계산한 것과 일치하는지 확인합니다.\n",
    "difference = np.linalg.norm(dists - dists_two, ord='fro')\n",
    "print 'Difference was: %f' % (difference, )\n",
    "if difference < 0.001:\n",
    "  print 'Good! The distance matrices are the same'\n",
    "else:\n",
    "  print 'Uh-oh! The distance matrices are different'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 구현한 것들이 얼마나 빠른지 비교합시다.\n",
    "def time_function(f, *args):\n",
    "  \"\"\"\n",
    "  Call a function f with args and return the time (in seconds) that it took to execute.\n",
    "  \"\"\"\n",
    "  import time\n",
    "  tic = time.time()\n",
    "  f(*args)\n",
    "  toc = time.time()\n",
    "  return toc - tic\n",
    "\n",
    "two_loop_time = time_function(classifier.compute_distances_two_loops, X_test)\n",
    "print 'Two loop version took %f seconds' % two_loop_time\n",
    "\n",
    "one_loop_time = time_function(classifier.compute_distances_one_loop, X_test)\n",
    "print 'One loop version took %f seconds' % one_loop_time\n",
    "\n",
    "no_loop_time = time_function(classifier.compute_distances_no_loops, X_test)\n",
    "print 'No loop version took %f seconds' % no_loop_time\n",
    "\n",
    "# 완전 벡터화 구현이 훨씬 더 빠른 성능을 낸다는것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차검증\n",
    "\n",
    "우리는 k-Nearest Neighbor 분류기를 구현했지만 임의로 k = 5라는 값을 정했습니다. 이제 hyperparameter의 교차검증으로 최선의 값을 결정할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
    "\n",
    "X_train_folds = []\n",
    "y_train_folds = []\n",
    "####################################################################################\n",
    "# TODO:                                                                            #\n",
    "# 폴더에 훈련 데이터를 분류합니다.                                                 #\n",
    "# 분류 후에, X_train_folds 와 y_train_folds는 y_train_folds[i]가                   #\n",
    "# X_train_folds[i]의 점에 대한 레이블 벡터인 num_folds의 길이의 목록이어야 합니다. #\n",
    "# 힌트: numpy의 array_split 함수를 살펴보세요.                                     #\n",
    "####################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                                    코드의 끝                                #\n",
    "################################################################################\n",
    "\n",
    "# 사전은 서로 다른 교차 검증을 실행할 때 찾은 k의 값에 대한 정확도를 가지고 있습니다.\n",
    "# k_to_accuracies[k]는 'num_folds' 길이의 리스트로 \n",
    "# 각기 다른 k 값을 사용할 때의 정확도를 담고있습니다.\n",
    "k_to_accuracies = {}\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "# TODO:                                                                            #\n",
    "# 최고의 k 값을 찾기 위해 k-fold 교차 검증을 수행합니다.                           #\n",
    "# 가능한 각 k에 대해서, k-nearest-neighbor 알고리즘을 numpy의num_folds회 실행합니다.#\n",
    "# 각각의 경우에 모두 사용하되 그 중 하나는 훈련 데이터로,                          #\n",
    "# 마지막 하나는 검증 데이터로 사용합니다.                                          #\n",
    "####################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                                    코드의 끝                                 #\n",
    "################################################################################\n",
    "\n",
    "# 계산된 정확도를 출력합니다.\n",
    "for k in sorted(k_to_accuracies):\n",
    "    for accuracy in k_to_accuracies[k]:\n",
    "        print 'k = %d, accuracy = %f' % (k, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 원시 관측 플롯\n",
    "for k in k_choices:\n",
    "  accuracies = k_to_accuracies[k]\n",
    "  plt.scatter([k] * len(accuracies), accuracies)\n",
    "\n",
    "# 표준편차에 해당하는 오차 막대와 추세선을 그립니다.\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 위의 교차검증 결과에 기반해서 최적의 k를 선택하고 모든 학습 데이터를 \n",
    "# 이용하여 분류기를 재학습 시키고 테스트 데이터를 이용해 테스트 해봅니다.\n",
    "# 테스트데이터에 대해서 28%이상의 정확도를 얻을 수 있어야 합니다.\n",
    "best_k = 1\n",
    "\n",
    "classifier = KNearestNeighbor()\n",
    "classifier.train(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test, k=best_k)\n",
    "\n",
    "# 정확도를 계산하고 출력합니다.\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print 'Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
