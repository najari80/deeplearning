{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainerハンズオン: Pythonによるディープラーニング入門\n",
    "\n",
    "## 目的\n",
    "\n",
    "ニューラルネットワークを用いた画像認識タスクを通じてChainerの使い方と特徴を理解する\n",
    "\n",
    "## このハンズオンで学べるChainerの特長\n",
    "\n",
    "1. デバッグのしやすさ\n",
    "2. CPUとGPUで共通のArray操作\n",
    "\n",
    "## 目次\n",
    "\n",
    "### Section 1. パーセプトロンによるMNIST画像分類\n",
    "\n",
    "単純なニューラルネットワークで数値画像の分類タスクに挑戦する\n",
    "\n",
    "* 多層パーセプトロンの構築と訓練\n",
    "* 結果の評価と可視化 \n",
    "* モデルの改良とデバッグ\n",
    "\n",
    "### Section 2. Chainerの基礎\n",
    "\n",
    "Chainerのデータ構造と実装の特徴をまとめる\n",
    "\n",
    "* NumPyとCuPy\n",
    "* VariableとFunction\n",
    "* LinkとChain\n",
    "* Define-by-Run\n",
    "\n",
    "## 注記\n",
    "\n",
    "このJupyter notebookはNVIDIA製GPUを搭載したマシンにCUDA7.0とChainer v1.8.0がインストールされた環境を想定している。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備: Chainerのインポート\n",
    "\n",
    "最初にChainerと関連モジュールをインポートする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Chainer \n",
    "from chainer import Chain, Variable, optimizers, serializers, datasets, training\n",
    "from chainer.training import extensions\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import chainer\n",
    "\n",
    "# Import NumPy and CuPy\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "# Utilities\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChainerはGPU計算のバックエンドでCuPyを使っている。CuPyはNumpyのサブセットであり同じインターフェースを提供している為、ユーザーはハードウェアを意識する事なく、共通のコードを動かす事が出来るというメリットがある。\n",
    "学習時には、GPUを使う事で計算の高速化が可能であり、CuPyは大変強力なライブラリである。CuPyについては後ほど説明する。\n",
    "\n",
    "Chainerのバージョン、CUDAの使用の可否、実行環境のCUDA計算可能なGPUの数などは以下のコマンドで取得可能だ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from chainer import cuda\n",
    "import cupy.cuda.runtime as CR\n",
    "\n",
    "# Get Chainer version\n",
    "print('Chainer version: ', chainer.__version__)\n",
    "\n",
    "# checking CUDA status. When CUDA is correctly set up, nothing happens.\n",
    "cuda.check_cuda_available()\n",
    "\n",
    "# getting gpu device count\n",
    "g_num = CR.getDeviceCount()\n",
    "\n",
    "# getting gpu info\n",
    "\n",
    "print '\\nGPU info'\n",
    "print '-------------------------------'   \n",
    "for i in xrange(g_num):\n",
    "    print '(ID):',i,' (CC):',cuda.get_device(i).compute_capability\n",
    "    print '-------------------------------'   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. パーセプトロンによるMNIST画像分類\n",
    "\n",
    "MNISTは機械学習でよく用いられる分類問題のベンチマークデータセットである。手書き数値文字画像を7万サンプル含み、それぞれに0から9までの正解ラベルが与えられている。タスクは、与えられた画像の数値を予測することであり、10クラス分類問題に相当する。\n",
    "\n",
    "<img src=\"image/mnist.png\">\n",
    "\n",
    "各サンプルは縦横28x28のグレースケール画像（784次元ベクトル）である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 定義: 多層パーセプトロン(2層)\n",
    "\n",
    "最も単純なニューラルネットワークモデルとして、2層の多層パーセプトロン（MLP2）を用いる。それは入力と出力、およびその間に1つの隠れユニットを持つ。2つの線形レイヤー（全結合層）がそれらの間にあり、それぞれ重み行列とバイアス項をパラメータとして内蔵している。隠れユニットに対する活性化関数はtanhを用いる、\n",
    "\n",
    "<img src=\"image/mlp_tanh.png\" width=\"600\" >\n",
    "\n",
    "以下がMLP2を実装したクラスである。コンストラクタ(``__init__``)の中では各レイヤーの種類と大きさしか定義されていないことに注意したい。実際の順方向計算は別の``__call__``メソッド内に直接書かれている。一方、逆方向計算は明示的に与えられてない。なぜなら、Chainerは順方向計算中に計算グラフを記憶し、それに沿って逆方向計算を行うからである（詳しくはSection 2で述べる）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2-layer Multi-Layer Perceptron (MLP)\n",
    "class MLP2(Chain):\n",
    "    \n",
    "    # Initialization of layers\n",
    "    def __init__(self):\n",
    "        super(MLP2, self).__init__(\n",
    "            l1=L.Linear(784, 100),  # From 784-dimensional input to hidden unit with 100 nodes \n",
    "            l2=L.Linear(100, 10),  # From hidden unit with 100 nodes to output unit with 10 nodes  (10 classes)\n",
    "        )\n",
    "\n",
    "    # Forward computation by __call__\n",
    "    def __call__(self, x):\n",
    "        h1 = F.tanh(self.l1(x))     # Forward from x to h1 through activation with tanh function \n",
    "        y = self.l2(h1)                 # Forward from h1to y\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備: MNISTデータセット読み込み＆前処理\n",
    "\n",
    "MNISTデータセットをchainer.datasets.get_mnist()を使ってメモリ上に読み込む。\n",
    "\n",
    "元の70,000サンプルを2つに分け、60,000サンプルの訓練用データセット（x_trainとy_trainのペア）と、10,000サンプルのテスト用データセット（x_testとy_testのペア）を用意する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = chainer.datasets.get_mnist()\n",
    "print('Train:', len(train))\n",
    "print('Test:', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備: 実験セットアップ\n",
    "\n",
    "以下の変数は実験を通して使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [] # Store all of the experimental results\n",
    "batchsize = 100 # Size of minibatches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1.1 - CPUを用いたMLP2の訓練\n",
    "\n",
    "最初の実験として、CPUベースでNumPyを用いた訓練を行う。エポック数（n_epoch、各サンプルが訓練中に何度使われるか）は2に固定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enable_cupy = False # No CuPy (Use NumPy)\n",
    "n_epoch=2 # Only 2 epochs\n",
    "model = MLP2() # MLP2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義: MNISTの訓練とテストを行うメソッド\n",
    "\n",
    "下のtrain_and_test()は実際に実験を走らせるメソッドで、Chainer v1.11.0から導入された[Trainer](http://docs.chainer.org/en/stable/tutorial/basic.html#trainer)を用いている。内容は以下の様な標準的な機械学習ワークフローの後ろ3つの処理を含んでいる。\n",
    "\n",
    "<img src=\"image/ml_flow.png\" width=\"600\">\n",
    "\n",
    "Optimizerは誤差逆伝搬によってモデルのパラメータ（ここではMLP2中の線形レイヤー中の重み行列とバイアス項）を更新するために使われる。Chainerはよく使われる最適化アルゴリズムの多くを[サポート](http://docs.chainer.org/en/stable/reference/optimizers.html#optimizers) している(SGD, AdaGrad, RMSProp, Adam, etc...)。ここではSGDを用いる。[L.Classifier](https://github.com/pfnet/chainer/blob/master/chainer/links/model/classifier.py) はニューラルネットワーク（ここではMLP2）を内蔵した分類モデルを表す。デフォルトの損失関数はSoftmax cross entropyである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def  train_and_test():\n",
    "    training_start = time.clock()\n",
    "    log_trigger = 600, 'iteration'\n",
    "    classifier_model = L.Classifier(model)\n",
    "    device = -1\n",
    "    if enable_cupy:\n",
    "        model.to_gpu()\n",
    "        chainer.cuda.get_device(0).use()\n",
    "        device = 0\n",
    "    optimizer = optimizers.SGD()\n",
    "    optimizer.setup(classifier_model)\n",
    "    train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "    test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)\n",
    "    updater = training.StandardUpdater(train_iter, optimizer, device=device)\n",
    "    trainer = training.Trainer(updater, (n_epoch, 'epoch'), out='out')\n",
    "    trainer.extend(extensions.dump_graph('main/loss'))\n",
    "    trainer.extend(extensions.Evaluator(test_iter, classifier_model, device=device))\n",
    "    trainer.extend(extensions.LogReport(trigger=log_trigger))\n",
    "    trainer.extend(extensions.PrintReport(\n",
    "        ['epoch', 'iteration', 'main/loss', 'validation/main/loss',\n",
    "         'main/accuracy', 'validation/main/accuracy']), trigger=log_trigger)\n",
    "    trainer.run()\n",
    "    elapsed_time = time.clock() - training_start\n",
    "    print('Elapsed time: %3.3f' % elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 実行: \"test finished\"が表示されれば完了\n",
    "\n",
    "ここで実験を走らせて最初の結果を得る。30秒かそれ以上かかる場合もある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_and_test() # May take 30 sec or more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価: 1回目の結果を確認する\n",
    "\n",
    "精度（accuracy）は90%に届かない程度だと思われる。悪くはないが、今後の実験で性能向上を目指す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 準備: 可視化ツールのインポート\n",
    "\n",
    "Pythonでは標準的なmatplotlibを計算グラフと画像の可視化に用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Import utility and visualization tools\n",
    "import pydot\n",
    "import pydotplus\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import Image, display\n",
    "import chainer.computational_graph as cg\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義: 計算グラフの可視化メソッド\n",
    "\n",
    "Chainerは入力から損失関数までの計算グラフを出力できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_graph():\n",
    "    cwd = os.getcwd()\n",
    "    print cwd\n",
    "    graph = pydotplus.graph_from_dot_file('out/cg.dot') # load from .dot file\n",
    "    graph.write_png('graph.png')\n",
    "\n",
    "    img = Image('graph.png', width=600, height=600)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: MLP2の計算グラフ可視化\n",
    "\n",
    "display_graph()を実行することで、有向グラフが表示される。一番上の3つの楕円形がそれぞれ784次元の画像100サンプル、線形レイヤーの対応する784x100の大きさの重み行列、長さ100のバイアス項ベクトル、を表す。\n",
    "\n",
    "中間の隠れユニット（100x100）は活性化関数tanhを通して次の線形レイヤーの入力となる。ニューラルネットワークの出力である長さ10の100ベクトルは正解であるint32のリストと比較され、SoftmaxCrossEntropy関数によって損失がfloat32の値として算出される。\n",
    "\n",
    "このグラフを構築したあと、誤差逆伝搬が末端の損失から入力までを遡り、モデルのパラメータ（2つの線形レイヤーの係数行列とバイアス項）を更新する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義: 画像と予測ラベルのプロット\n",
    "\n",
    "テスト用データセットのMNIST画像60サンプルをプロットする。画像上部の\"Answer\"がデータセットで与えられた正解であり、\"Predict\"が現在の分類モデルによる予測結果である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_examples():\n",
    "    %matplotlib inline\n",
    "    plt.figure(figsize=(12,50))\n",
    "    if enable_cupy:\n",
    "       model.to_cpu()\n",
    "    for i in range(45, 105): \n",
    "        x = Variable(np.asarray([test[i][0]]))  # test data\n",
    "        t = Variable(np.asarray([test[i][1]]))  # labels\n",
    "        y = model(x)\n",
    "        prediction = y.data.argmax(axis=1)\n",
    "        example = (test[i][0] * 255).astype(np.int32).reshape(28, 28)\n",
    "        plt.subplot(20, 5, i - 44)\n",
    "        plt.imshow(example, cmap='gray')\n",
    "        plt.title(\"No.{0} / Answer:{1}, Predict:{2}\".format(i, t.data[0], prediction[0]))\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: いくつかのサンプルが誤分類される\n",
    "\n",
    "多くのサンプルの数字は正しく分類されているが、誤りも見受けられる。例えば、一行目のNo. 46の画像が'3'と予測されているかもしれないが、人間には正解の通り'1'に見える。同様に、いびつな形をした'6'である二行目のNo. 54を'2'と誤分類していないだろうか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " plot_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1.2 - エポック数を増加させてみる\n",
    "\n",
    "精度向上のために、単にエポック数を増加させることを試みる。他の設定は全て同一のままである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enable_cupy = False\n",
    "n_epoch=5                 # Increased from 2 to 5\n",
    "model = MLP2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: エポック数5で再実験\n",
    "\n",
    "エポック数が増えたので実験終了にはより長い時間がかかる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_and_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価: テスト精度が向上していることを確認\n",
    "\n",
    "前回と比べ損失の値が低減され精度が向上（90%以上）となっていることがわかる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: 誤分類が減ったか確認\n",
    "\n",
    "先ほど誤分類されたNo.46もしくはNo.54が今回正しく分類されているか確認してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1.3 - CuPyでGPUを計算に使う\n",
    "\n",
    "エポック数を増やすことで精度は向上したが、エポック数5ですでに1分以上かかっている。次のケースでは、CuPyを有効にしてGPUを使うことでこの訓練を高速化する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enable_cupy = True # Now use CuPy\n",
    "n_epoch=5\n",
    "model = MLP2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: 同じモデルをGPUで訓練\n",
    "\n",
    "（GPU計算の立ち上がりに時間がかかるが）各エポックの実行速度が明らかに違うことがわかる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_and_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価: 訓練の高速化結果を確認する\n",
    "\n",
    "実行時間を比べると、GPUによる訓練はCPUに比べて5倍以上である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1.4 - レイヤーを追加する\n",
    "\n",
    "今度はレイヤーを増やした異なる多層パーセプトロンを用いる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義: 3層の多層パーセプトロン\n",
    "\n",
    "以下のMLP3は3つの線形レイヤーでつながれた同じ100ノードからなる2つの隠れユニットを持つ。順方向計算でtanhを活性化関数を用いるのも同様である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3-layer multi-Layer Perceptron (MLP)\n",
    "class MLP3(Chain):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MLP3, self).__init__(\n",
    "            l1=L.Linear(784, 100),\n",
    "            l2=L.Linear(100, 100),   # Additional  layer\n",
    "            l3=L.Linear(100, 10)\n",
    "        )\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h1 = F.tanh(self.l1(x))   # Hidden unit 1\n",
    "        h2 = F.tanh(self.l2(h1)) # Hidden unit 2\n",
    "        y = self.l3(h2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備: 分類モデルのベースをMLP3とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enable_cupy = True\n",
    "n_epoch=5\n",
    "model = MLP3()  # Use MLP3 instead of MLP2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution: 新しいMLP3ベースのモデルを訓練する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_and_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価: MLP2とMLP3の精度を比較する\n",
    "\n",
    "MLP3は高い表現力によって、MLP2よりも低い損失と高い精度を達成している。一方、内部パラメータも増えるため、訓練に要する時間はわずかに増加する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: MLP3ベースの計算グラフを表示\n",
    "\n",
    "新しい計算グラフは3つのLinearFunctionと2つのTanh活性化関数を含む。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: 誤分類サンプルはもうないか？\n",
    "\n",
    "現在のモデルは先ほどと同様の60サンプルであればほぼ完璧に予測できることが確認できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainerの特長 - (1) デバッグのしやすさ\n",
    "\n",
    "複雑なニューラルネットワークのデバッグは面倒である、何故なら一般のフレームワークはモデル定義や実装のどこが間違っているのか、直接的には教えてくれない事が多いからだ。しかしChainerでは普通のプログラムをデバッグするかのように行うことができ、順方向計算中の型チェックもサポートしている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義: 予めバグを埋め込んだMLP実装\n",
    "\n",
    "以下のMLP3Wrongは、MLP3に3つのバグをわざと埋め込んだものである。実行しながら1つ1つ解決していこう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find three bugs in this model definition\n",
    "class MLP3Wrong(Chain):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MLP3Wrong, self).__init__(\n",
    "            l1=L.Linear(748, 100),\n",
    "            l2=L.Linear(100, 100),\n",
    "            l3=L.Linear(100, 10) \n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.tanh(self.l1(x))\n",
    "        h2 = F.tanh(self.l2(x))\n",
    "        y = self.l3(h3)\n",
    "        return y\n",
    "    \n",
    "enable_cupy = True\n",
    "n_epoch=5\n",
    "model = L.Classifier(MLP3Wrong()) # MLP3Wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: スタックトレースを見るとエラー箇所が判る\n",
    "\n",
    "以下を実行するとエラーが発生するが、スタックトレースの表示を下まで追うとそれが順方向計算においてどのソースコードのどの行で発生しているかがわかる。これはChainerのDefine-by-Runが、計算グラフを順方向計算中に直接構築しているため可能なことである（Section 2で説明する）。\n",
    "\n",
    "3つのバグを修正し終わると、MLP3Wrongは先ほどのMLP3と一致するはずである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_and_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1.5 - 自分のモデルを作ってみよう\n",
    "\n",
    "それではあなたの番だ。モデルを自分で変更してさらに高い精度を目指してみよう。\n",
    "\n",
    "エポック数を増やして時間をかけるのは単純過ぎる解決策なので、エポック数10以下、かつ訓練時間100秒以内という制限の中で95％を超える精度を達成してみてほしい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義: オプションを駆使して新しいモデルを作る\n",
    "\n",
    "ニューラルネットワークモデルをチューニングしてパフォーマンスを向上させよう。以下の様なオプションがある。\n",
    "\n",
    "* エポック数を増やす\n",
    "* 各ユニットのノード数を増やす\n",
    "* レイヤー数を増やす\n",
    "* 異なる活性化関数を用いる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's create new Multi-Layer Perceptron (MLP)\n",
    "class MLPNew(Chain):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Add more layers?\n",
    "        super(MLPNew, self).__init__(\n",
    "            l1=L.Linear(784, 100),  # Increase output node as (784, 200)?\n",
    "            l2=L.Linear(100, 100),  # Increase nodes as (200, 200)?\n",
    "            l3=L.Linear(100, 10)      # Increase nodes as (200, 10)?\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))        # Replace F.tanh with F.sigmoid  or F.relu ?\n",
    "        h2 = F.relu(self.l2(h1))        # Replace F.tanh with F.sigmoid  or F.relu ?\n",
    "        y = self.l3(h2)\n",
    "        return y\n",
    "\n",
    "enable_cupy = True #  Use CuPy for faster training\n",
    "n_epoch = 5 # Add more epochs?\n",
    "model = MLPNew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 実行: 95%以上の精度をもつモデルができただろうか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_and_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: もう失敗しない？\n",
    "\n",
    "95%以上の精度があれば、おそらく誤判別は見当たらないはずである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: 自分の作ったベストなモデルの内部を見てみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 発展: 畳み込みニューラルネットワークの実装\n",
    "\n",
    "このセクションでは、線形（全結合）層を持つ多層パーセプトロンのみを用いた。しかしながら、最近の画像認識におけるディープラーニングの進化は、畳み込みニューラルネットワーク（Convolutional Neural Network; CNN）という異なるタイプがもたらしている。\n",
    "\n",
    "このハンズオンの内容を超えるためその詳細はここでは割愛するが、ChainerはImageNet画像分類タスクの[example](https://github.com/pfnet/chainer/tree/master/examples/imagenet)に、様々な畳み込みニューラルネットワークの実装を含んでいる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義: AlexNetモデル (ImageNetコンテスト2012優勝)\n",
    "\n",
    "AlexNetは最も標準的なCNNで、ImageNet2012コンテストで優勝したモデルである。\n",
    "\n",
    "基本的な関数やレイヤーは全てChainerでサポートされているため、ユーザーがこのような標準的なCNNを再実装したり、自分の問題のために拡張できる。例えばAlexNetは以下の様なモジュールを含んでいる。\n",
    "\n",
    "* Convolutional layer (L.Convolution2D)\n",
    "* Max pooling (F.max_pooling_2d)\n",
    "* Local response normalization (F.local_response_normalization)\n",
    "* Dropout (F.dropout)\n",
    "\n",
    "関数等の詳細については、Chainerリファレンスマニュアルの[Standard Function implementations](http://docs.chainer.org/en/stable/reference/functions.html)に説明がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definition of AlexNet\n",
    "class AlexNet(chainer.Chain):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__(\n",
    "            conv1=L.Convolution2D(3,  96, 11, stride=4),\n",
    "            conv2=L.Convolution2D(96, 256,  5, pad=2),\n",
    "            conv3=L.Convolution2D(256, 384,  3, pad=1),\n",
    "            conv4=L.Convolution2D(384, 384,  3, pad=1),\n",
    "            conv5=L.Convolution2D(384, 256,  3, pad=1),\n",
    "            fc6=L.Linear(9216, 4096),\n",
    "            fc7=L.Linear(4096, 4096),\n",
    "            fc8=L.Linear(4096, 1000),\n",
    "        )\n",
    "        self.train = True\n",
    "        \n",
    "    def __call__(self, x, t):\n",
    "        self.clear()\n",
    "        h = F.max_pooling_2d(F.relu(\n",
    "            F.local_response_normalization(self.conv1(x))), 3, stride=2)\n",
    "        h = F.max_pooling_2d(F.relu(\n",
    "            F.local_response_normalization(self.conv2(h))), 3, stride=2)\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = F.relu(self.conv4(h))\n",
    "        h = F.max_pooling_2d(F.relu(self.conv5(h)), 3, stride=2)\n",
    "        h = F.dropout(F.relu(self.fc6(h)), train=self.train)\n",
    "        h = F.dropout(F.relu(self.fc7(h)), train=self.train)\n",
    "        y = self.fc8(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Section 2. Chainerの基礎\n",
    "\n",
    "Section 1では、画像認識をタスク例に、Chainerにおいてどのようにしてニューラルネットワークを定義し訓練するかを説明した。\n",
    "\n",
    "ユーザーはこのようなパターン認識タスクだけでなく、自分の課題にもChainerを利用できる。しかし、上記の課題ではプリセットに存在するレイヤーや関数を組み合わせるだけでニューラルネットワークを構築していたが、今後はユーザーがゼロからより低レベルのコーディングを行うことで新しいネットワークを作り出す必要があるかもしれない。\n",
    "\n",
    "Chainerはそのようなユーザーが新しいモデルを迅速にプロトタイピングし、テストし、トライアンドエラーを通じて改良しやすいようにデザインされている。以下では、Chainerのコアとなっているコンポーネントについて説明する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.1 NumPyとCuPy\n",
    "\n",
    "NumPyはPythonの数値計算用に広く用いられているライブラリであり、Chainerの中でも用いられている。一方、ニューラルネットワークはGPGPUの多次元配列演算の高速化を必要としている。しかしNumPyはGPUをサポートしていないため、Chainerの初期バージョンではGPUを用いるためにはGPUに特化したコードを常に必要としていた。\n",
    "\n",
    "そこでChainer開発陣は、NumPy互換性のあるCUDAライブラリとしてCuPyを開発し、Chainerに加えた。CuPyは現在NumPyの多くのAPIをサポートしていおり、ユーザーはほとんどの場合CPU/GPU非依存なコードを書くことができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: NumPyを試す\n",
    "\n",
    "NumPyを用いて、行列の生成と処理を行って処理時間を計測する。具体的には、1000x1000の大きさの行列を作り、転置し、各要素を2倍にする操作を5000回繰り返す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "a = np.arange(1000000).reshape(1000, -1)\n",
    "t1 = time.clock()\n",
    "for i in range(5000):\n",
    "    a = np.arange(1000000).reshape(1000, -1)\n",
    "    b = a.T * 2\n",
    "t2 = time.clock()\n",
    "print(t2 -t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 実行: CuPyを試す\n",
    "\n",
    "同じ処理をCuPyで試す。1行目の実行はCUDA関連の初期化に時間がかかるが、5000回のループ処理全体はNumPyと比べて4倍かそれ以上高速になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import cupy as cp\n",
    "a = cp.arange(1000000).reshape(1000, -1)\n",
    "t1 = time.clock()\n",
    "for i in range(5000):\n",
    "    a = cp.arange(1000000).reshape(1000, -1)\n",
    "    b = a.T * 2\n",
    "t2 = time.clock()\n",
    "print(t2 -t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Chainerの特長 - (2) CPU/GPU互換の行列演算\n",
    "\n",
    "CuPyは可能な限りNumPyと同じインタフェースを提供しているため、ユーザーは計算ロジックを変更すること無く両者を以下のように切り替えられる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xp_test(xp):\n",
    "    a = xp.arange(1000000).reshape(1000, -1)\n",
    "    t1 = time.clock()\n",
    "    for i in range(5000):\n",
    "        a = xp.arange(1000000).reshape(1000, -1)\n",
    "        b = a.T * 2\n",
    "    t2 = time.clock()\n",
    "    print(t2 -t1)\n",
    "\n",
    "enable_cupy = False\n",
    "xp_test(np if not enable_cupy else cp)\n",
    "enable_cupy = True\n",
    "xp_test(np if not enable_cupy else cp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.2 VariableとFunction\n",
    "\n",
    "VariableとFunctionはそれぞれChainerで基礎的なクラスである。その名前から分かる通り、Variableは変数の値を表し、FunctionはVariableに対する操作を行う（静的な）関数である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: Variableは多次元配列を含むクラス\n",
    "\n",
    "VariableはNumPyかCuPyの多次元配列インスタンスと共に初期化され、その値は.dataに格納される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Variable(np.asarray([[0, 2],[1, -3]]).astype(np.float32))\n",
    "\n",
    "print(type(x))\n",
    "print(type(x.data))\n",
    "print(x.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: VariableはCPUとGPUの間を移動できる\n",
    "\n",
    "to_gpu()やto_cpu()を呼ぶことで、.dataを含むVariable内の要素はCPU側のNumPyの多次元配列、GPU側のCuPyの多次元配列を行き来できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.to_gpu()\n",
    "print(type(x.data))\n",
    "x.to_cpu()\n",
    "print(type(x.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: FunctionはVariableの変換を行う\n",
    "\n",
    "実際の計算はforward（）メソッド中に記述され、出力もまたVariableのインスタンスになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from chainer import function\n",
    "\n",
    "class MyFunc(function.Function):\n",
    "    def forward(self, x):\n",
    "        self.y = x[0] **2 + 2 * x[0] + 1 # y = x^2 + 2x + 1\n",
    "        return self.y,\n",
    "\n",
    "def my_func(x):\n",
    "    return MyFunc()(x)\n",
    "\n",
    "x = Variable(np.asarray([[0, 2],[1, -3]]).astype(np.float32))\n",
    "y = my_func(x)\n",
    "print(type(x))\n",
    "print(x.data)\n",
    "print(type(y))\n",
    "print(y.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: Variableは履歴を記憶する\n",
    "\n",
    "各Variableのインスタンスは自分を生成したFunctionを.creator以下に記憶している。それがNoneの場合、そのVariableインスタンスはrootと呼ばれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Variable(np.asarray([[0, 2],[1, -3]]).astype(np.float32))\n",
    "\n",
    "# y is created by MyFunc\n",
    "y = my_func(x)\n",
    "print(y.creator)\n",
    "\n",
    "# z is created by F.sigmoid\n",
    "z = F.sigmoid(x)\n",
    "print(z.creator)\n",
    "\n",
    "# x is created by user\n",
    "print(x.creator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  説明: Variableは誤差逆伝搬をネイティブサポートしている\n",
    "\n",
    "誤差逆伝搬法（backpropagation）はニューラルネットワークを最適化する標準的な手法である。順方向計算のあと、出力に対して損失関数の値が勾配として与えられると、計算グラフを逆順に辿って、各中間ノードに対する勾配が与えられる。そして、その勾配情報を元に各パラメータの値が更新される。\n",
    "\n",
    "<img src=\"image/backward.png\" width=\"250\">\n",
    "\n",
    "Chainerでは、自動微分がサポートされ、かつ順方向計算中に全てのVariableインスタンスが記録されているため、勾配（.grad）をセットされた出力Variableにたいしてbackward()メソッドを呼ぶと、計算グラフ上をroot（つまり.creatorがNoneである入力ユニットのノード）まで遡って誤差逆伝搬が動作する。その後、Optimizerがモデル（のパラメータ）を更新する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義: 順方向計算としての2次式\n",
    "\n",
    "前のSectionで示したように、順方向計算は、最終的な出力Variableを生成するための演算の連鎖と見なすことができる。その間、Chainerは全ての中間Variableインスタンスを記録している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A mock of forward computation\n",
    "def forward(x):\n",
    "    z = 2 * x\n",
    "    y = x ** 2 - z + 1\n",
    "    return y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: 勾配を与えるための逆方向計算\n",
    "\n",
    "y.gradに勾配をセットしy.backward()を実行することで、勾配情報がxとzにまで伝わる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Variable(np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32))\n",
    "y, z = forward(x)\n",
    "y.grad = np.ones((2, 3), dtype=np.float32)\n",
    "y.backward(retain_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gradient for x: 2*x - 2\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gradient for z: -1\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.3 LinkとChain\n",
    "\n",
    "Functionは内部状態を持たない特定の演算のみを表していたため、ニューラルネットワーク中のレイヤーのように、パラメータを表す状態を持つ要素としては直接用いることができない。\n",
    "\n",
    "Linkは、そのような演算へのラッパーとなり、状態を持つ。Linkが再利用可能なモジュールとして定義されるため、大きなネットワーク（後述するChainのインスタンス）の部品として用いることができる。多くの標準的なレイヤーは[chianer.links](http://docs.chainer.org/en/stable/reference/links.html)中に用意されており、これまで用いてきたL.Linearと同様に、L.XYZというカタチで利用できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 実行: Linkはパラメータを持つ状態付き関数\n",
    "\n",
    "Linkクラスの多くのコンストラクタは内部パラメータと大きさを表すようないくつかの引数を持つ。それらのパラメータも、Variableのインスタンスとして表現される。\n",
    "\n",
    "例えば、L.Linearは2つのパラメータ、係数行列のWとバイアス項のbを持つ。L.Linearのコンストラクタはそれらのサイズを決定する2つの引数を持つ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = L.Linear(3, 2)\n",
    "# Weight matrix for linear transformation (randomly initialized)\n",
    "print(f.W.data)\n",
    "# Bias term for linear transformation (initialized with zero)\n",
    "print(f.b.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 実行: Linkのインスタンスを使う\n",
    "\n",
    "Linkのインスタンスは関数のように、直接呼び出すことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply linear transformation f()\n",
    "x = Variable(np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32))\n",
    "y = f(x)\n",
    "print(y.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行: Linkに対して勾配を計算する\n",
    "\n",
    "Link内のパラメータがVariableのインスタンスのため、逆方向計算はそれらにも勾配を与える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize gradients of f\n",
    "f.zerograds()\n",
    "# Set gradient of y (= loss)\n",
    "y.grad = np.ones((2, 2), dtype=np.float32)\n",
    "# Backward computation\n",
    "y.backward()\n",
    "# Gradient for f.W and f.b\n",
    "print(f.W.grad)\n",
    "print(f.b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義: ChainerはLinkの集合、つまりネットワークを表す\n",
    "\n",
    "以下のクラスはSection 1で扱ったMLP2そのものであるが、Chainクラスを継承している。ニューラルネットワークを表す基底クラスとして、Chainerはパラメータの管理や、CPU/GPU間のto_cpu()とto_gpu()、モデルのシリアライズとファイルへの保存／読み込みなどをサポートしている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2-layer Multi-Layer Perceptron (MLP)\n",
    "class MLP2(Chain):\n",
    "    \n",
    "    # Initialization of layers (Link)\n",
    "    def __init__(self):\n",
    "        super(MLP2, self).__init__(\n",
    "            l1=L.Linear(784, 100),\n",
    "            l2=L.Linear(100, 10),\n",
    "        )\n",
    "\n",
    "    # Forward computation by __call__\n",
    "    def __call__(self, x):\n",
    "        h1 = F.tanh(self.l1(x))\n",
    "        y = self.l2(h1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 発展: Define-by-Runというアプローチ\n",
    "\n",
    "既存ディープラーニングフレームワークのほとんどでは、モデルの構築と訓練は2つの分離したプロセスとして扱われる。具体的には訓練の前に、モデルの定義（モデル記述テキストやシンボリックなプログラム記述）に従って計算グラフを構築して固定している。この場合のモデル定義は、ディープラーニング用のドメイン特化言語（Domain Specific Language; DSL）の一種と考えられる。その後、訓練データセットを与えられ、実際の訓練プロセスに寄ってモデルを更新する。下の図はその2つのプロセスを表現している。我々はこれをDefine-and-Runと読んでいる。\n",
    "\n",
    "<img src=\"image/define-and-run.png\" width=\"400\">\n",
    "\n",
    "Define-and-Runは極めて著感的で、かつ訓練の前に計算グラフを最適化しやすいという特徴をもっている。一方、そのデメリットもある。例えば、リカレントニューラルネットワークのようなモデルを記述するときには、特殊な文法を用いる必要がある。また、ネットワークが動的に変化する、例えば部分的に追加・削除される場合でも、可能性のある計算グラフの全てを訓練の最初から最後までメモリ上に保持しておく必要があるため、メモリ効率の面で最適とはいえない場合がある。\n",
    "\n",
    "それゆえに、ChainerではDefine-by-Runを名付けた異なるアプローチを採用している。ここではモデルの定義が訓練と同時に順方向計算として与えられており、その場で計算グラフが構築される。これによってユーザーはループや条件分岐などを含む複雑なニューラルネットワークを、ホスト言語であるPythonの文法そのままを使って、容易に実装できる。また、Truncated  BPTTのような計算グラフへの変更も、効率的に行われる。\n",
    "\n",
    "<img src=\"image/define-by-run.png\" width=\"400\">\n",
    "\n",
    "さらなる詳細に興味のあるユーザーは[論文](http://learningsys.org/papers/LearningSys_2015_paper_33.pdf)を参照してほしい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3. まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このnotebookではChainerを柔軟で直感的、かつパワフルなディープラーニングフレームワークとして紹介した。特に、最近の学術論文で提案されている複雑なニューラルネットワークモデルを容易に再実装したい時や、新しいアルゴリズムのプロトタイプを実装する際に、Chainerは威力を発揮する。\n",
    "\n",
    "以下の画像は有名な [\"A neural algorithm of Artistic style\"](http://arxiv.org/abs/1508.06576)という論文の[Chainer実装](https://github.com/mattya/chainer-gogh)によって生成されたものである。\n",
    "\n",
    "猫のコンテンツ画像が、横にある様々なスタイル画像と同様の画風となるように再描画されているのがわかる。\n",
    "\n",
    "<img src=\"image/gogh.png\" width=\"500\">\n",
    "\n",
    "これは単なる一例に過ぎないが、githubのコードを見るとこのような面白いモデルがChainerを使って数百行で再実装できていることがお分かりいただけると思う。\n",
    "その他にも、ユーザーが様々なユースケースで作成した[コード例のリスト](https://github.com/pfnet/chainer/wiki/External-examples)があるので、参考になれば幸いである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "これで本notebookは終了である。さらなる詳細は[公式チュートリアル](http://docs.chainer.org/en/stable/tutorial/index.html)を参照されたい。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
